{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デルタレイク クイックスタート Delta Lake Quickstart\n",
    "https://docs.delta.io/latest/quick-start.html#python\n",
    "\n",
    "# 本サンプルの目的 Ovjective\n",
    "データのUPSERT例<br>\n",
    "削除フラグのある論理削除を想定している<br>\n",
    "Example of UPSERT of data<br>\n",
    "Assumes logical deletion with delete flag\n",
    "\n",
    "# データ概要 Data Summary\n",
    "## ターゲットデータ Target data\n",
    "`/workspace/csv/products_10.csv`<br>\n",
    "ターゲットデータは、永続化されたデルタテーブルで、Lakehouseとしての用途を想定している<br>\n",
    "Target data is a persistent delta table, intended for use as a Lakehouse\n",
    "| id | name | short_name | kind | material | price | description | delete_flg |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | Fantastic Granite Pizza | Shoes | Small | Cotton | 3067 | nothing | 0 |\n",
    "| 2 | Rustic Soft Fish | Pants | Handmade | Steel | 7107 | nothing | 0 |\n",
    "| 3 | Licensed Cotton Hat | Sausages | Fantastic | Metal | 9050 | nothing | 0 |\n",
    "| 4 | Luxurious Bronze Towels | Chair | Intelligent | Plastic | 4967 | nothing | 0 |\n",
    "| 5 | Generic Wooden Towels | Mouse | Small | Metal | 4428 | still | 0 |\n",
    "| 6 | Handcrafted Cotton Sausages | Computer | Licensed | Plastic | 5047 | update | 0 |\n",
    "| 7 | Handmade Wooden Towels | Chips | Small | Steel | 7796 | update | 0 |\n",
    "| 8 | Licensed Metal Fish | Computer | Refined | Rubber | 7437 | delete_flg | 0 |\n",
    "| 9 | Electronic Concrete Chair | Cheese | Incredible | Metal | 1062 | delete_flg | 0 |\n",
    "| 10 | Incredible Metal Computer | Pants | Unbranded | Rubber | 6368 | delete_flg | 0 |\n",
    "\n",
    "## ソースデータ Source data\n",
    "`/workspace/csv/products_15.csv`<br>\n",
    "ソースデータは、ELTの際に、ターゲットデータにデータを挿入する前にデータを挿入する一時テーブルとしての用途を想定している<br>\n",
    "一時テーブルなので、使い終わったら削除をしたいが、アンマネージドテーブルは削除ができないので要注意<br>\n",
    "※マネージドテーブルだと削除ができる<br>\n",
    "Source data is intended to be used as a temporary table to insert data before inserting data into target data during ELT<br>\n",
    "Since it is a temporary table, you want to delete it when you are done using it, but be aware that unmanaged tables cannot be deleted.<br>\n",
    "※Managed table allows deletion.\n",
    "| id | name | short_name | kind | material | price | description | delete_flg |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 5 | Generic Wooden Towels | Mouse | Small | Metal | 4428 | still | 0 |\n",
    "| 6 | Handcrafted Cotton Sausages | Computer | 1 | 1 | 1 | update | 0 |\n",
    "| 7 | Handmade Wooden Towels | Chips | 1 | 1 | 1 | update | 0 |\n",
    "| 8 | Licensed Metal Fish | Computer | Refined | Rubber | 7437 | delete_flg | 1 |\n",
    "| 9 | Electronic Concrete Chair | Cheese | Incredible | Metal | 1062 | delete_flg | 1 |\n",
    "| 10 | Incredible Metal Computer | Pants | Unbranded | Rubber | 6368 | delete_flg | 1 |\n",
    "| 11 | Oriental Rubber Gloves | Hat | Electronic | Metal | 7357 | insert | 0 |\n",
    "| 12 | Elegant Soft Pizza | Hat | Practical | Cotton | 6231 | insert | 0 |\n",
    "| 13 | Sleek Plastic Salad | Soap | Refined | Frozen | 9682 | insert | 0 |\n",
    "| 14 | Refined Fresh Sausages | Tuna | Ergonomic | Granite | 3528 | insert | 0 |\n",
    "| 15 | Elegant Steel Ball | Bacon | Rustic | Metal | 9283 | insert | 0 |\n",
    "\n",
    "## UPSERT後のデータ Data after UPSERT\n",
    "`/workspace/tables/products`<br>\n",
    "ターゲットデータにソースデータをUPSERTした結果、得られる予定のデータ<br>\n",
    "Data expected to result from UPSERT of source data to target data\n",
    "| id | name | short_name | kind | material | price | description | delete_flg |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 1 | Fantastic Granite Pizza | Shoes | Small | Cotton | 3067 | nothing | 0 |\n",
    "| 2 | Rustic Soft Fish | Pants | Handmade | Steel | 7107 | nothing | 0 |\n",
    "| 3 | Licensed Cotton Hat | Sausages | Fantastic | Metal | 9050 | nothing | 0 |\n",
    "| 4 | Luxurious Bronze Towels | Chair | Intelligent | Plastic | 4967 | nothing | 0 |\n",
    "| 5 | Generic Wooden Towels | Mouse | Small | Metal | 4428 | still | 0 |\n",
    "| 6 | Handcrafted Cotton Sausages | Computer | 1 | 1 | 1 | update | 0 |\n",
    "| 7 | Handmade Wooden Towels | Chips | 1 | 1 | 1 | update | 0 |\n",
    "| 8 | Licensed Metal Fish | Computer | Refined | Rubber | 7437 | delete_flg | 1 |\n",
    "| 9 | Electronic Concrete Chair | Cheese | Incredible | Metal | 1062 | delete_flg | 1 |\n",
    "| 10 | Incredible Metal Computer | Pants | Unbranded | Rubber | 6368 | delete_flg | 1 |\n",
    "| 11 | Oriental Rubber Gloves | Hat | Electronic | Metal | 7357 | insert | 0 |\n",
    "| 12 | Elegant Soft Pizza | Hat | Practical | Cotton | 6231 | insert | 0 |\n",
    "| 13 | Sleek Plastic Salad | Soap | Refined | Frozen | 9682 | insert | 0 |\n",
    "| 14 | Refined Fresh Sausages | Tuna | Ergonomic | Granite | 3528 | insert | 0 |\n",
    "| 15 | Elegant Steel Ball | Bacon | Rustic | Metal | 9283 | insert | 0 |\n",
    "\n",
    "# 処理イメージ\n",
    "```mermaid\n",
    "flowchart TB\n",
    "  TD([name : Target data\\npath : /workspace/csv/products_10.csv\\ntype : csv])\n",
    "  SD([name : Source data\\npath : /workspace/csv/products_15.csv\\ntype : csv])\n",
    "\n",
    "  DFTD[name : csvDf\\ntype : dataformat]\n",
    "  DFSD[name : csvDfTmp\\ntype : dataformat]\n",
    "\n",
    "  DTTD[(name : products\\npath : /workspace/tables/products\\ntype : Delta table)]\n",
    "  DTSD[(products_tmp\\n/workspace/tables/products_tmp\\ntype : Delta table)]\n",
    "\n",
    "  TD-->|spark.read|DFTD\n",
    "  SD-->|spark.read|DFSD\n",
    "\n",
    "  DFTD-->|write\\noverwrite|DTTD\n",
    "  DFSD-->|write\\noverwrite|DTSD\n",
    "\n",
    "  DTSD-->|upsert\\nkey = id|DTTD\n",
    "```\n",
    "※処理フローは要件によって変わってくるので、あくまでも参考とすること<br>\n",
    "The processing flow will vary depending on requirements and should be used as a reference only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/usr/local/lib/python3.11/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/vscode/.ivy2/cache\n",
      "The jars for the packages stored in: /home/vscode/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-6b0fab98-d165-439c-be94-02af12ed7fe6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.0.0 in central\n",
      "\tfound io.delta#delta-storage;3.0.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 217ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.0.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.0.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-6b0fab98-d165-439c-be94-02af12ed7fe6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/10ms)\n",
      "23/11/08 06:08:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from delta import *\n",
    "from delta.tables import *\n",
    "import packages.modules as modules\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StringType, StructField, StructType\n",
    "\n",
    "builder = pyspark.sql.SparkSession.builder.appName(\"MyApp\") \\\n",
    "  .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "spark.conf.set(\"spark.sql.debug.maxToStringFields\", 1000)\n",
    "\n",
    "workspace = \"/workspace\"\n",
    "file_name = \"products_10\"\n",
    "file_name_tmp = \"products_15\"\n",
    "file_ext = \".csv\"\n",
    "data_path = workspace + \"/csv/\" + file_name + file_ext\n",
    "data_path_tmp = workspace + \"/csv/\" + file_name_tmp + file_ext\n",
    "delta_table_name = \"products\"\n",
    "delta_table_name_tmp = \"products_tmp\"\n",
    "delta_table_path = workspace + \"/tables/\" + delta_table_name\n",
    "delta_table_path_tmp = workspace + \"/tables/\" + delta_table_name_tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 処理開始\n",
    "products_10のcsvデータを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- short_name: string (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      " |-- material: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- delete_flg: string (nullable = true)\n",
      "\n",
      "+---+--------------------+----------+-----------+--------+-----+-----------+----------+\n",
      "| id|                name|short_name|       kind|material|price|description|delete_flg|\n",
      "+---+--------------------+----------+-----------+--------+-----+-----------+----------+\n",
      "|  1|Fantastic Granite...|     Shoes|      Small|  Cotton| 3067|    nothing|         0|\n",
      "|  2|    Rustic Soft Fish|     Pants|   Handmade|   Steel| 7107|    nothing|         0|\n",
      "|  3| Licensed Cotton Hat|  Sausages|  Fantastic|   Metal| 9050|    nothing|         0|\n",
      "|  4|Luxurious Bronze ...|     Chair|Intelligent| Plastic| 4967|    nothing|         0|\n",
      "|  5|Generic Wooden To...|     Mouse|      Small|   Metal| 4428|      still|         0|\n",
      "|  6|Handcrafted Cotto...|  Computer|   Licensed| Plastic| 5047|     update|         0|\n",
      "|  7|Handmade Wooden T...|     Chips|      Small|   Steel| 7796|     update|         0|\n",
      "|  8| Licensed Metal Fish|  Computer|    Refined|  Rubber| 7437| delete_flg|         0|\n",
      "|  9|Electronic Concre...|    Cheese| Incredible|   Metal| 1062| delete_flg|         0|\n",
      "| 10|Incredible Metal ...|     Pants|  Unbranded|  Rubber| 6368| delete_flg|         0|\n",
      "+---+--------------------+----------+-----------+--------+-----+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvDf = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(data_path)\n",
    "csvDf.printSchema()\n",
    "csvDf.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "product_15のcsvデータを取得する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- short_name: string (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      " |-- material: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- delete_flg: string (nullable = true)\n",
      "\n",
      "+---+--------------------+----------+----------+--------+-----+-----------+----------+\n",
      "| id|                name|short_name|      kind|material|price|description|delete_flg|\n",
      "+---+--------------------+----------+----------+--------+-----+-----------+----------+\n",
      "|  5|Generic Wooden To...|     Mouse|     Small|   Metal| 4428|      still|         0|\n",
      "|  6|Handcrafted Cotto...|  Computer|         1|       1|    1|     update|         0|\n",
      "|  7|Handmade Wooden T...|     Chips|         1|       1|    1|     update|         0|\n",
      "|  8| Licensed Metal Fish|  Computer|   Refined|  Rubber| 7437| delete_flg|         1|\n",
      "|  9|Electronic Concre...|    Cheese|Incredible|   Metal| 1062| delete_flg|         1|\n",
      "| 10|Incredible Metal ...|     Pants| Unbranded|  Rubber| 6368| delete_flg|         1|\n",
      "| 11|Oriental Rubber G...|       Hat|Electronic|   Metal| 7357|     insert|         0|\n",
      "| 12|  Elegant Soft Pizza|       Hat| Practical|  Cotton| 6231|     insert|         0|\n",
      "| 13| Sleek Plastic Salad|      Soap|   Refined|  Frozen| 9682|     insert|         0|\n",
      "| 14|Refined Fresh Sau...|      Tuna| Ergonomic| Granite| 3528|     insert|         0|\n",
      "| 15|  Elegant Steel Ball|     Bacon|    Rustic|   Metal| 9283|     insert|         0|\n",
      "+---+--------------------+----------+----------+--------+-----+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvDfTmp = spark.read.option(\"delimiter\", \",\").option(\"header\", \"true\").csv(data_path_tmp)\n",
    "csvDfTmp.printSchema()\n",
    "csvDfTmp.show(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デルタテーブルにデータを書き込む\n",
    "ローカル環境上で`saveAsTable`を使おうとすると、エラーが発生する。<br>\n",
    "原因は、今の所、調査中。<br>\n",
    "なので、`save`を使って、データを書き込んでいる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csvDf.write\\\n",
    "  .format(\"delta\")\\\n",
    "  .mode(\"overwrite\")\\\n",
    "  .partitionBy(\"kind\")\\\n",
    "  .save(delta_table_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "csvDfTmp.write\\\n",
    "  .format(\"delta\")\\\n",
    "  .mode(\"overwrite\")\\\n",
    "  .partitionBy(\"kind\")\\\n",
    "  .save(delta_table_path_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デルタテーブルをUpsertする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deltaTable = DeltaTable.forPath(spark, delta_table_path)\n",
    "deltaTableTmp = DeltaTable.forPath(spark, delta_table_path_tmp)\n",
    "dfTemp = deltaTableTmp.toDF()\n",
    "\n",
    "deltaTable.alias(\"products\")\\\n",
    "  .merge(\n",
    "    source = dfTemp.alias(\"tableTmp\"),\n",
    "    condition = \"products.id = tableTmp.id\"\n",
    "  )\\\n",
    "  .whenMatchedUpdateAll()\\\n",
    "  .whenNotMatchedInsertAll()\\\n",
    "  .execute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# デルタテーブルを読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------+-----------+--------+-----+-----------+----------+\n",
      "| id|                name|short_name|       kind|material|price|description|delete_flg|\n",
      "+---+--------------------+----------+-----------+--------+-----+-----------+----------+\n",
      "|  1|Fantastic Granite...|     Shoes|      Small|  Cotton| 3067|    nothing|         0|\n",
      "|  2|    Rustic Soft Fish|     Pants|   Handmade|   Steel| 7107|    nothing|         0|\n",
      "|  3| Licensed Cotton Hat|  Sausages|  Fantastic|   Metal| 9050|    nothing|         0|\n",
      "|  4|Luxurious Bronze ...|     Chair|Intelligent| Plastic| 4967|    nothing|         0|\n",
      "|  5|Generic Wooden To...|     Mouse|      Small|   Metal| 4428|      still|         0|\n",
      "|  6|Handcrafted Cotto...|  Computer|          1|       1|    1|     update|         0|\n",
      "|  7|Handmade Wooden T...|     Chips|          1|       1|    1|     update|         0|\n",
      "|  8| Licensed Metal Fish|  Computer|    Refined|  Rubber| 7437| delete_flg|         1|\n",
      "|  9|Electronic Concre...|    Cheese| Incredible|   Metal| 1062| delete_flg|         1|\n",
      "| 10|Incredible Metal ...|     Pants|  Unbranded|  Rubber| 6368| delete_flg|         1|\n",
      "| 11|Oriental Rubber G...|       Hat| Electronic|   Metal| 7357|     insert|         0|\n",
      "| 12|  Elegant Soft Pizza|       Hat|  Practical|  Cotton| 6231|     insert|         0|\n",
      "| 13| Sleek Plastic Salad|      Soap|    Refined|  Frozen| 9682|     insert|         0|\n",
      "| 14|Refined Fresh Sau...|      Tuna|  Ergonomic| Granite| 3528|     insert|         0|\n",
      "| 15|  Elegant Steel Ball|     Bacon|     Rustic|   Metal| 9283|     insert|         0|\n",
      "+---+--------------------+----------+-----------+--------+-----+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "df.createOrReplaceTempView(delta_table_name)\n",
    "spark.conf.set('dq.val.delta_table_name', delta_table_name)\n",
    "spark.sql(\n",
    "  \"\"\"\n",
    "    SELECT\n",
    "      id,\n",
    "      name,\n",
    "      short_name,\n",
    "      kind,\n",
    "      material,\n",
    "      price,\n",
    "      description,\n",
    "      delete_flg\n",
    "    FROM ${dq.val.delta_table_name}\n",
    "    ORDER BY CAST(id AS BIGINT) ASC\n",
    "  \"\"\"\n",
    ").show(100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
